{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2220e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/7900',\n",
       "  'repository_url': 'https://api.github.com/repos/huggingface/datasets',\n",
       "  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/labels{/name}',\n",
       "  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/comments',\n",
       "  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/events',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/issues/7900',\n",
       "  'id': 3711751590,\n",
       "  'node_id': 'I_kwDODunzps7dPNWm',\n",
       "  'number': 7900,\n",
       "  'title': '`Permission denied` when sharing cache between users',\n",
       "  'user': {'login': 'qthequartermasterman',\n",
       "   'id': 19497738,\n",
       "   'node_id': 'MDQ6VXNlcjE5NDk3NzM4',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/19497738?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/qthequartermasterman',\n",
       "   'html_url': 'https://github.com/qthequartermasterman',\n",
       "   'followers_url': 'https://api.github.com/users/qthequartermasterman/followers',\n",
       "   'following_url': 'https://api.github.com/users/qthequartermasterman/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/qthequartermasterman/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/qthequartermasterman/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/qthequartermasterman/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/qthequartermasterman/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/qthequartermasterman/repos',\n",
       "   'events_url': 'https://api.github.com/users/qthequartermasterman/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/qthequartermasterman/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'labels': [],\n",
       "  'state': 'open',\n",
       "  'locked': False,\n",
       "  'assignee': None,\n",
       "  'assignees': [],\n",
       "  'milestone': None,\n",
       "  'comments': 0,\n",
       "  'created_at': '2025-12-09T16:41:47Z',\n",
       "  'updated_at': '2025-12-09T16:42:19Z',\n",
       "  'closed_at': None,\n",
       "  'author_association': 'NONE',\n",
       "  'type': None,\n",
       "  'active_lock_reason': None,\n",
       "  'sub_issues_summary': {'total': 0, 'completed': 0, 'percent_completed': 0},\n",
       "  'issue_dependencies_summary': {'blocked_by': 0,\n",
       "   'total_blocked_by': 0,\n",
       "   'blocking': 0,\n",
       "   'total_blocking': 0},\n",
       "  'body': '### Describe the bug\\n\\nWe want to use `datasets` and `transformers` on a shared machine. Right now, each user has a separate HF_HOME in their home directory. To reduce duplicates of the datasets, we want to share that cache. While experimenting, we are running into `Permission denied` errors.\\n\\nIt looks like this was supported in the past (see #6589)?\\n\\nIs there a correct way to share caches across users?\\n\\n### Steps to reproduce the bug\\n\\n1. Create a directory `/models/hf_hub_shared_experiment` with read/write permissions for two different users\\n2. For each user run the script below\\n\\n```python\\nimport os\\n\\nos.environ[\"HF_HOME\"] = \"/models/hf_hub_shared_experiment\"\\nos.environ[\"HF_DATASETS_CACHE\"] = \"/models/hf_hub_shared_experiment/data\"\\n\\nimport datasets\\nimport transformers\\n\\nDATASET = \"tatsu-lab/alpaca\"\\nMODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\\n\\nmodel = transformers.AutoModelForCausalLM.from_pretrained(MODEL)\\ntokenizer = transformers.AutoTokenizer.from_pretrained(MODEL)\\ndataset = datasets.load_dataset(DATASET)\\n```\\n\\nThe first user is able to download and use the model and dataset. The second user gets these errors:\\n\\n```\\n$ python ./experiment_with_shared.py\\nCould not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/hub/models--meta-llama--Llama-3.2-1B-Instruct/.no_exist/9213176726f574b556790deb65791e0c5aa438b6/custom_generate/generate.py\\'\\nCould not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/hub/datasets--tatsu-lab--alpaca/.no_exist/dce01c9b08f87459cf36a430d809084718273017/alpaca.py\\'\\nCould not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/hub/datasets--tatsu-lab--alpaca/.no_exist/dce01c9b08f87459cf36a430d809084718273017/.huggingface.yaml\\'\\nCould not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/hub/datasets--tatsu-lab--alpaca/.no_exist/dce01c9b08f87459cf36a430d809084718273017/dataset_infos.json\\'\\nTraceback (most recent call last):\\n  File \"/home/user2/.venv/experiment_with_shared.py\", line 17, in <module>\\n    dataset = datasets.load_dataset(DATASET)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/datasets/load.py\", line 1397, in load_dataset\\n    builder_instance = load_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/datasets/load.py\", line 1171, in load_dataset_builder\\n    builder_instance: DatasetBuilder = builder_cls(\\n                                       ^^^^^^^^^^^^\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/datasets/builder.py\", line 390, in __init__\\n    with FileLock(lock_path):\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/filelock/_api.py\", line 377, in __enter__\\n    self.acquire()\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/filelock/_api.py\", line 333, in acquire\\n    self._acquire()\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/filelock/_unix.py\", line 45, in _acquire\\n    fd = os.open(self.lock_file, open_flags, self._context.mode)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nPermissionError: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/data/_models_hf_hub_shared_experiment_data_tatsu-lab___alpaca_default_0.0.0_dce01c9b08f87459cf36a430d809084718273017.lock\\'\\n```\\n\\n### Expected behavior\\n\\nThe second user should be able to read the shared cache files.\\n\\n### Environment info\\n\\n$ datasets-cli env\\n\\n- `datasets` version: 4.4.1\\n- Platform: Linux-6.8.0-88-generic-x86_64-with-glibc2.39\\n- Python version: 3.12.3\\n- `huggingface_hub` version: 0.36.0\\n- PyArrow version: 22.0.0\\n- Pandas version: 2.3.3\\n- `fsspec` version: 2025.10.0',\n",
       "  'closed_by': None,\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/reactions',\n",
       "   'total_count': 1,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 1},\n",
       "  'timeline_url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/timeline',\n",
       "  'performed_via_github_app': None,\n",
       "  'state_reason': None}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1\"\n",
    "response = requests.get(url)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eeb8945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a9f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "load_dotenv()  # reads .env into environment\n",
    "\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "\n",
    "# Example GET request\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49dc9664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/7900', 'repository_url': 'https://api.github.com/repos/huggingface/datasets', 'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/labels{/name}', 'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/comments', 'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/events', 'html_url': 'https://github.com/huggingface/datasets/issues/7900', 'id': 3711751590, 'node_id': 'I_kwDODunzps7dPNWm', 'number': 7900, 'title': '`Permission denied` when sharing cache between users', 'user': {'login': 'qthequartermasterman', 'id': 19497738, 'node_id': 'MDQ6VXNlcjE5NDk3NzM4', 'avatar_url': 'https://avatars.githubusercontent.com/u/19497738?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/qthequartermasterman', 'html_url': 'https://github.com/qthequartermasterman', 'followers_url': 'https://api.github.com/users/qthequartermasterman/followers', 'following_url': 'https://api.github.com/users/qthequartermasterman/following{/other_user}', 'gists_url': 'https://api.github.com/users/qthequartermasterman/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/qthequartermasterman/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/qthequartermasterman/subscriptions', 'organizations_url': 'https://api.github.com/users/qthequartermasterman/orgs', 'repos_url': 'https://api.github.com/users/qthequartermasterman/repos', 'events_url': 'https://api.github.com/users/qthequartermasterman/events{/privacy}', 'received_events_url': 'https://api.github.com/users/qthequartermasterman/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False}, 'labels': [], 'state': 'open', 'locked': False, 'assignee': None, 'assignees': [], 'milestone': None, 'comments': 0, 'created_at': '2025-12-09T16:41:47Z', 'updated_at': '2025-12-09T16:42:19Z', 'closed_at': None, 'author_association': 'NONE', 'type': None, 'active_lock_reason': None, 'sub_issues_summary': {'total': 0, 'completed': 0, 'percent_completed': 0}, 'issue_dependencies_summary': {'blocked_by': 0, 'total_blocked_by': 0, 'blocking': 0, 'total_blocking': 0}, 'body': '### Describe the bug\\n\\nWe want to use `datasets` and `transformers` on a shared machine. Right now, each user has a separate HF_HOME in their home directory. To reduce duplicates of the datasets, we want to share that cache. While experimenting, we are running into `Permission denied` errors.\\n\\nIt looks like this was supported in the past (see #6589)?\\n\\nIs there a correct way to share caches across users?\\n\\n### Steps to reproduce the bug\\n\\n1. Create a directory `/models/hf_hub_shared_experiment` with read/write permissions for two different users\\n2. For each user run the script below\\n\\n```python\\nimport os\\n\\nos.environ[\"HF_HOME\"] = \"/models/hf_hub_shared_experiment\"\\nos.environ[\"HF_DATASETS_CACHE\"] = \"/models/hf_hub_shared_experiment/data\"\\n\\nimport datasets\\nimport transformers\\n\\nDATASET = \"tatsu-lab/alpaca\"\\nMODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\\n\\nmodel = transformers.AutoModelForCausalLM.from_pretrained(MODEL)\\ntokenizer = transformers.AutoTokenizer.from_pretrained(MODEL)\\ndataset = datasets.load_dataset(DATASET)\\n```\\n\\nThe first user is able to download and use the model and dataset. The second user gets these errors:\\n\\n```\\n$ python ./experiment_with_shared.py\\nCould not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/hub/models--meta-llama--Llama-3.2-1B-Instruct/.no_exist/9213176726f574b556790deb65791e0c5aa438b6/custom_generate/generate.py\\'\\nCould not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/hub/datasets--tatsu-lab--alpaca/.no_exist/dce01c9b08f87459cf36a430d809084718273017/alpaca.py\\'\\nCould not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/hub/datasets--tatsu-lab--alpaca/.no_exist/dce01c9b08f87459cf36a430d809084718273017/.huggingface.yaml\\'\\nCould not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/hub/datasets--tatsu-lab--alpaca/.no_exist/dce01c9b08f87459cf36a430d809084718273017/dataset_infos.json\\'\\nTraceback (most recent call last):\\n  File \"/home/user2/.venv/experiment_with_shared.py\", line 17, in <module>\\n    dataset = datasets.load_dataset(DATASET)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/datasets/load.py\", line 1397, in load_dataset\\n    builder_instance = load_dataset_builder(\\n                       ^^^^^^^^^^^^^^^^^^^^^\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/datasets/load.py\", line 1171, in load_dataset_builder\\n    builder_instance: DatasetBuilder = builder_cls(\\n                                       ^^^^^^^^^^^^\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/datasets/builder.py\", line 390, in __init__\\n    with FileLock(lock_path):\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/filelock/_api.py\", line 377, in __enter__\\n    self.acquire()\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/filelock/_api.py\", line 333, in acquire\\n    self._acquire()\\n  File \"/home/user2/.venv/lib/python3.12/site-packages/filelock/_unix.py\", line 45, in _acquire\\n    fd = os.open(self.lock_file, open_flags, self._context.mode)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nPermissionError: [Errno 13] Permission denied: \\'/models/hf_hub_shared_experiment/data/_models_hf_hub_shared_experiment_data_tatsu-lab___alpaca_default_0.0.0_dce01c9b08f87459cf36a430d809084718273017.lock\\'\\n```\\n\\n### Expected behavior\\n\\nThe second user should be able to read the shared cache files.\\n\\n### Environment info\\n\\n$ datasets-cli env\\n\\n- `datasets` version: 4.4.1\\n- Platform: Linux-6.8.0-88-generic-x86_64-with-glibc2.39\\n- Python version: 3.12.3\\n- `huggingface_hub` version: 0.36.0\\n- PyArrow version: 22.0.0\\n- Pandas version: 2.3.3\\n- `fsspec` version: 2025.10.0', 'closed_by': None, 'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/reactions', 'total_count': 1, '+1': 0, '-1': 0, 'laugh': 0, 'hooray': 0, 'confused': 0, 'heart': 0, 'rocket': 0, 'eyes': 1}, 'timeline_url': 'https://api.github.com/repos/huggingface/datasets/issues/7900/timeline', 'performed_via_github_app': None, 'state_reason': None}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "response = requests.get(\"https://api.github.com/repos/huggingface/datasets/issues?per_page=1\", headers=headers)\n",
    "print(response.status_code)\n",
    "print(response.json())\n",
    "\n",
    "def fetch_issues(\n",
    "    owner=\"huggingface\",\n",
    "    repo=\"datasets\",\n",
    "    num_issues=10_000,\n",
    "    rate_limit=5_000,\n",
    "    issues_path=Path(\"../data/hf_github_issues\"),\n",
    "):\n",
    "    if not issues_path.is_dir():\n",
    "        issues_path.mkdir(exist_ok=True)\n",
    "\n",
    "    batch = []\n",
    "    all_issues = []\n",
    "    per_page = 100  # Number of issues to return per page\n",
    "    num_pages = math.ceil(num_issues / per_page)\n",
    "    base_url = \"https://api.github.com/repos\"\n",
    "\n",
    "    for page in tqdm(range(num_pages)):\n",
    "        # Query with state=all to get both open and closed issues\n",
    "        query = f\"issues?page={page}&per_page={per_page}&state=all\"\n",
    "        issues = requests.get(f\"{base_url}/{owner}/{repo}/{query}\", headers=headers)\n",
    "        batch.extend(issues.json())\n",
    "\n",
    "        if len(batch) > rate_limit and len(all_issues) < num_issues:\n",
    "            all_issues.extend(batch)\n",
    "            batch = []  # Flush batch for next time period\n",
    "            print(f\"Reached GitHub rate limit. Sleeping for one hour ...\")\n",
    "            time.sleep(60 * 60 + 1)\n",
    "\n",
    "    all_issues.extend(batch)\n",
    "    df = pd.DataFrame.from_records(all_issues)\n",
    "    df.to_json(f\"{issues_path}/{repo}-issues.jsonl\", orient=\"records\", lines=True)\n",
    "    print(\n",
    "        f\"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9df2c6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84e1835dfaf474aae0e06ee83381ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached GitHub rate limit. Sleeping for one hour ...\n",
      "Downloaded all the issues for datasets! Dataset stored at ../data/hf_github_issues/datasets-issues.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Depending on your internet connection, this can take several minutes to run...\n",
    "fetch_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cabb96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'type', 'active_lock_reason', 'sub_issues_summary', 'issue_dependencies_summary', 'body', 'closed_by', 'reactions', 'timeline_url', 'performed_via_github_app', 'state_reason', 'draft', 'pull_request'],\n",
       "    num_rows: 7818\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to Dataset\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"../data/hf_github_issues/datasets-issues.jsonl\", lines=True)\n",
    "issues_dataset = Dataset.from_pandas(df)\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d6e919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> URL: https://github.com/huggingface/datasets/pull/316\n",
      ">> Pull Request: {'diff_url': 'https://github.com/huggingface/datasets/pull/316.diff', 'html_url': 'https://github.com/huggingface/datasets/pull/316', 'merged_at': '2020-06-30T08:31:55Z', 'patch_url': 'https://github.com/huggingface/datasets/pull/316.patch', 'url': 'https://api.github.com/repos/huggingface/datasets/pulls/316'}\n",
      "\n",
      ">> URL: https://github.com/huggingface/datasets/issues/854\n",
      ">> Pull Request: None\n",
      "\n",
      ">> URL: https://github.com/huggingface/datasets/pull/3647\n",
      ">> Pull Request: {'diff_url': 'https://github.com/huggingface/datasets/pull/3647.diff', 'html_url': 'https://github.com/huggingface/datasets/pull/3647', 'merged_at': '2022-01-28T15:35:57Z', 'patch_url': 'https://github.com/huggingface/datasets/pull/3647.patch', 'url': 'https://api.github.com/repos/huggingface/datasets/pulls/3647'}\n",
      "\n",
      ">> URL: https://github.com/huggingface/datasets/issues/5855\n",
      ">> Pull Request: None\n",
      "\n",
      ">> URL: https://github.com/huggingface/datasets/pull/5795\n",
      ">> Pull Request: {'diff_url': 'https://github.com/huggingface/datasets/pull/5795.diff', 'html_url': 'https://github.com/huggingface/datasets/pull/5795', 'merged_at': '2023-04-26T17:39:12Z', 'patch_url': 'https://github.com/huggingface/datasets/pull/5795.patch', 'url': 'https://api.github.com/repos/huggingface/datasets/pulls/5795'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Examine HTML and pull requests\n",
    "sample = issues_dataset.shuffle(seed=42).select(range(5))\n",
    "for url, pr in zip(sample[\"html_url\"], sample[\"pull_request\"]):\n",
    "    print(f\">> URL: {url}\")\n",
    "    print(f\">> Pull Request: {pr}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03049995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2402bf908d4dc3bbbeded913f30cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new field indicating whether the issue is a pull request\n",
    "issue_dataset = issues_dataset.map(\n",
    "    lambda example: {\"is_pull_request\": False if example[\"pull_request\"] is None else True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4b6b823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128',\n",
       "  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',\n",
       "  'id': 897594128,\n",
       "  'node_id': 'IC_kwDODunzps41gDMQ',\n",
       "  'user': {'login': 'bhavitvyamalik',\n",
       "   'id': 19718818,\n",
       "   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/bhavitvyamalik',\n",
       "   'html_url': 'https://github.com/bhavitvyamalik',\n",
       "   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',\n",
       "   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',\n",
       "   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'created_at': '2021-08-12T12:21:52Z',\n",
       "  'updated_at': '2021-08-12T12:31:17Z',\n",
       "  'body': \"@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?\",\n",
       "  'author_association': 'CONTRIBUTOR',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'performed_via_github_app': None},\n",
       " {'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/898644889',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-898644889',\n",
       "  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',\n",
       "  'id': 898644889,\n",
       "  'node_id': 'IC_kwDODunzps41kDuZ',\n",
       "  'user': {'login': 'bhavitvyamalik',\n",
       "   'id': 19718818,\n",
       "   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/bhavitvyamalik',\n",
       "   'html_url': 'https://github.com/bhavitvyamalik',\n",
       "   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',\n",
       "   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',\n",
       "   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'created_at': '2021-08-13T18:28:27Z',\n",
       "  'updated_at': '2021-08-13T18:28:27Z',\n",
       "  'body': 'Thanks for the help, @albertvillanova! All tests are passing now.',\n",
       "  'author_association': 'CONTRIBUTOR',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/898644889/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'performed_via_github_app': None}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine comments for a specific issue\n",
    "issue_number = 2792\n",
    "url = f\"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments\"\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e72add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?\",\n",
       " 'Thanks for the help, @albertvillanova! All tests are passing now.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get comments\n",
    "def get_comments(issue_number):\n",
    "    url = f\"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return [r[\"body\"] for r in response.json()]\n",
    "issue_number = 2792\n",
    "comments = get_comments(issue_number)\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3f3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1cc7274f8f4060a2e5b167d78b4f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a new comments column to the dataset\n",
    "issues_with_comments_dataset = issue_dataset.map(\n",
    "    lambda example: {\"comments\": get_comments(example[\"number\"])}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset to the Hub\n",
    "issues_with_comments_dataset.push_to_hub(\"hf-datasets-github-issues-with-comments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "from datasets import load_dataset\n",
    "remote_dataset = load_dataset(\"tensor-polinomics/hf-datasets-github-issues-with-comments\")\n",
    "remote_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
