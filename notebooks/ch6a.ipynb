{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17c2a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['code', 'repo_name', 'path', 'language', 'license', 'size'],\n",
       "        num_rows: 45001\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['code', 'repo_name', 'path', 'language', 'license', 'size'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Python programming language corpus\n",
    "# Different from the course website (original data is no longer available)\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"theothertom/codeparrot-python-only\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d783be53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 45001\n",
      "Size: 360.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Check size\n",
    "print(f\"Rows: {len(raw_datasets['train'])}\")\n",
    "print(f\"Size: {raw_datasets['train'].data.nbytes / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43ced27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from django import forms\n",
      "from django.core.exceptions import ValidationError\n",
      "from django.core.validators import validate_slug\n",
      "from django.db import models\n",
      "from django.utils import simplejson as json\n",
      "from django.utils.text import capfirst\n",
      "from django.utils.translation import ugettext_lazy as _\n",
      "\n",
      "from philo.forms.fields import JSONFormField\n",
      "from philo.utils.registry import RegistryIterator\n",
      "from philo.validators import TemplateValidator, json_validator\n",
      "#from philo.models.fields.entities import *\n",
      "\n",
      "\n",
      "class TemplateField(models.TextField):\n",
      "\t\"\"\"A :class:`TextField` which is validated with a :class:`.TemplateValidator`. ``allow``, ``disallow``, and ``secure`` will be passed into the validator's construction.\"\"\"\n",
      "\tdef __init__(self, allow=None, disallow=None, secure=True, *args, **kwargs):\n",
      "\t\tsuper(TemplateField, self).__init__(*args, **kwargs)\n",
      "\t\tself.validators.append(TemplateValidator(allow, disallow, secure))\n",
      "\n",
      "\n",
      "class JSONDescriptor(object):\n",
      "\tdef __init__(self, field):\n",
      "\t\tself.field = field\n",
      "\t\n",
      "\tdef __get__(self, instance, owner):\n",
      "\t\tif instance is None:\n",
      "\t\t\traise AttributeError # ?\n",
      "\t\t\n",
      "\t\tif self.field.name not in instance.__dict__:\n",
      "\t\t\tjson_string = getattr(instance, self.field.attname)\n",
      "\t\t\tinstance.__dict__[self.field.name] = json.loads(json_string)\n",
      "\t\t\n",
      "\t\treturn instance.__dict__[self.field.name]\n",
      "\t\n",
      "\tdef __set__(self, instance, value):\n",
      "\t\tinstance.__dict__[self.field.name] = value\n",
      "\t\tsetattr(instance, self.field.attname, json.dumps(value))\n",
      "\t\n",
      "\tdef __delete__(self, instance):\n",
      "\t\tdel(instance.__dict__[self.field.name])\n",
      "\t\tsetattr(instance, self.field.attname, json.dumps(None))\n",
      "\n",
      "\n",
      "class JSONField(models.TextField):\n",
      "\t\"\"\"A :class:`TextField` which stores its value on the model instance as a python object and stores its value in the database as JSON. Validated with :func:`.json_validator`.\"\"\"\n",
      "\tdefault_validators = [json_validator]\n",
      "\t\n",
      "\tdef get_attname(self):\n",
      "\t\treturn \"%s_json\" % self.name\n",
      "\t\n",
      "\tdef contribute_to_class(self, cls, name):\n",
      "\t\tsuper(JSONField, self).contribute_to_class(cls, name)\n",
      "\t\tsetattr(cls, name, JSONDescriptor(self))\n",
      "\t\tmodels.signals.pre_init.connect(self.fix_init_kwarg, sender=cls)\n",
      "\t\n",
      "\tdef fix_init_kwarg(self, sender, args, kwargs, **signal_kwargs):\n",
      "\t\t# Anything passed in as self.name is assumed to come from a serializer and\n",
      "\t\t# will be treated as a json string.\n",
      "\t\tif self.name in kwargs:\n",
      "\t\t\tvalue = kwargs.pop(self.name)\n",
      "\t\t\t\n",
      "\t\t\t# Hack to handle the xml serializer's handling of \"null\"\n",
      "\t\t\tif value is None:\n",
      "\t\t\t\tvalue = 'null'\n",
      "\t\t\t\n",
      "\t\t\tkwargs[self.attname] = value\n",
      "\t\n",
      "\tdef formfield(self, *args, **kwargs):\n",
      "\t\tkwargs[\"form_class\"] = JSONFormField\n",
      "\t\treturn super(JSONField, self).formfield(*args, **kwargs)\n",
      "\n",
      "\n",
      "class SlugMultipleChoiceField(models.Field):\n",
      "\t\"\"\"Stores a selection of multiple items with unique slugs in the form of a comma-separated list. Also knows how to correctly handle :class:`RegistryIterator`\\ s passed in as choices.\"\"\"\n",
      "\t__metaclass__ = models.SubfieldBase\n",
      "\tdescription = _(\"Comma-separated slug field\")\n",
      "\t\n",
      "\tdef get_internal_type(self):\n",
      "\t\treturn \"TextField\"\n",
      "\t\n",
      "\tdef to_python(self, value):\n",
      "\t\tif not value:\n",
      "\t\t\treturn []\n",
      "\t\t\n",
      "\t\tif isinstance(value, list):\n",
      "\t\t\treturn value\n",
      "\t\t\n",
      "\t\treturn value.split(',')\n",
      "\t\n",
      "\tdef get_prep_value(self, value):\n",
      "\t\treturn ','.join(value)\n",
      "\t\n",
      "\tdef formfield(self, **kwargs):\n",
      "\t\t# This is necessary because django hard-codes TypedChoiceField for things with choices.\n",
      "\t\tdefaults = {\n",
      "\t\t\t'widget': forms.CheckboxSelectMultiple,\n",
      "\t\t\t'choices': self.get_choices(include_blank=False),\n",
      "\t\t\t'label': capfirst(self.verbose_name),\n",
      "\t\t\t'required': not self.blank,\n",
      "\t\t\t'help_text': self.help_text\n",
      "\t\t}\n",
      "\t\tif self.has_default():\n",
      "\t\t\tif callable(self.default):\n",
      "\t\t\t\tdefaults['initial'] = self.default\n",
      "\t\t\t\tdefaults['show_hidden_initial'] = True\n",
      "\t\t\telse:\n",
      "\t\t\t\tdefaults['initial'] = self.get_default()\n",
      "\t\t\n",
      "\t\tfor k in kwargs.keys():\n",
      "\t\t\tif k not in ('coerce', 'empty_value', 'choices', 'required',\n",
      "\t\t\t\t\t\t 'widget', 'label', 'initial', 'help_text',\n",
      "\t\t\t\t\t\t 'error_messages', 'show_hidden_initial'):\n",
      "\t\t\t\tdel kwargs[k]\n",
      "\t\t\n",
      "\t\tdefaults.update(kwargs)\n",
      "\t\tform_class = forms.TypedMultipleChoiceField\n",
      "\t\treturn form_class(**defaults)\n",
      "\t\n",
      "\tdef validate(self, value, model_instance):\n",
      "\t\tinvalid_values = []\n",
      "\t\tfor val in value:\n",
      "\t\t\ttry:\n",
      "\t\t\t\tvalidate_slug(val)\n",
      "\t\t\texcept ValidationError:\n",
      "\t\t\t\tinvalid_values.append(val)\n",
      "\t\t\n",
      "\t\tif invalid_values:\n",
      "\t\t\t# should really make a custom message.\n",
      "\t\t\traise ValidationError(self.error_messages['invalid_choice'] % invalid_values)\n",
      "\t\n",
      "\tdef _get_choices(self):\n",
      "\t\tif isinstance(self._choices, RegistryIterator):\n",
      "\t\t\treturn self._choices.copy()\n",
      "\t\telif hasattr(self._choices, 'next'):\n",
      "\t\t\tchoices, self._choices = itertools.tee(self._choices)\n",
      "\t\t\treturn choices\n",
      "\t\telse:\n",
      "\t\t\treturn self._choices\n",
      "\tchoices = property(_get_choices)\n",
      "\n",
      "\n",
      "try:\n",
      "\tfrom south.modelsinspector import add_introspection_rules\n",
      "except ImportError:\n",
      "\tpass\n",
      "else:\n",
      "\tadd_introspection_rules([], [\"^philo\\.models\\.fields\\.SlugMultipleChoiceField\"])\n",
      "\tadd_introspection_rules([], [\"^philo\\.models\\.fields\\.TemplateField\"])\n",
      "\tadd_introspection_rules([], [\"^philo\\.models\\.fields\\.JSONField\"])\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][0]['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18cf0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a generator function\n",
    "def get_training_corpus():\n",
    "    dataset = raw_datasets[\"train\"]\n",
    "    for start_idx in range(0, len(dataset), 1000):\n",
    "        samples = dataset[start_idx : start_idx + 1000]\n",
    "        yield samples[\"code\"]\n",
    "        \n",
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4eb6d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'Ġadd', '_', 'n', 'umbers', '(', 'a', ',', 'Ġb', '):', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġ\"\"\"', 'Add', 'Ġthe', 'Ġtwo', 'Ġnumbers', 'Ġ`', 'a', '`', 'Ġand', 'Ġ`', 'b', '`', '.\"', '\"\"', 'Ċ', 'Ġ', 'Ġ', 'Ġ', 'Ġreturn', 'Ġa', 'Ġ+', 'Ġb']\n"
     ]
    }
   ],
   "source": [
    "# Understand old tokenizer behavior\n",
    "from transformers import AutoTokenizer\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "example = '''def add_numbers(a, b):\n",
    "    \"\"\"Add the two numbers `a` and `b`.\"\"\"\n",
    "    return a + b'''\n",
    "\n",
    "print(old_tokenizer.tokenize(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f22764ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a new tokenizer from the corpus\n",
    "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcce9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['def', 'Ġadd', '_', 'numbers', '(', 'a', ',', 'Ġb', '):', 'ĊĠĠĠ', 'Ġ\"\"\"', 'Add', 'Ġthe', 'Ġtwo', 'Ġnumbers', 'Ġ`', 'a', '`', 'Ġand', 'Ġ`', 'b', '`.\"\"\"', 'ĊĠĠĠ', 'Ġreturn', 'Ġa', 'Ġ+', 'Ġb']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(example)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef70a7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(old_tokenizer.tokenize(example)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36641848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'ĠLinear',\n",
       " 'Layer',\n",
       " '():',\n",
       " 'ĊĠĠĠ',\n",
       " 'Ġdef',\n",
       " 'Ġ__',\n",
       " 'init',\n",
       " '__(',\n",
       " 'self',\n",
       " ',',\n",
       " 'Ġinput',\n",
       " '_',\n",
       " 'size',\n",
       " ',',\n",
       " 'Ġoutput',\n",
       " '_',\n",
       " 'size',\n",
       " '):',\n",
       " 'ĊĠĠĠĠĠĠĠ',\n",
       " 'Ġself',\n",
       " '.',\n",
       " 'weight',\n",
       " 'Ġ=',\n",
       " 'Ġtorch',\n",
       " '.',\n",
       " 'randn',\n",
       " '(',\n",
       " 'input',\n",
       " '_',\n",
       " 'size',\n",
       " ',',\n",
       " 'Ġoutput',\n",
       " '_',\n",
       " 'size',\n",
       " ')',\n",
       " 'ĊĠĠĠĠĠĠĠ',\n",
       " 'Ġself',\n",
       " '.',\n",
       " 'bias',\n",
       " 'Ġ=',\n",
       " 'Ġtorch',\n",
       " '.',\n",
       " 'zeros',\n",
       " '(',\n",
       " 'output',\n",
       " '_',\n",
       " 'size',\n",
       " ')',\n",
       " 'ĊĊĠĠĠ',\n",
       " 'Ġdef',\n",
       " 'Ġ__',\n",
       " 'call',\n",
       " '__(',\n",
       " 'self',\n",
       " ',',\n",
       " 'Ġx',\n",
       " '):',\n",
       " 'ĊĠĠĠĠĠĠĠ',\n",
       " 'Ġreturn',\n",
       " 'Ġx',\n",
       " 'Ġ@',\n",
       " 'Ġself',\n",
       " '.',\n",
       " 'weights',\n",
       " 'Ġ+',\n",
       " 'Ġself',\n",
       " '.',\n",
       " 'bias',\n",
       " 'ĊĠĠĠĠ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"\"\"class LinearLayer():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weight = torch.randn(input_size, output_size)\n",
    "        self.bias = torch.zeros(output_size)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.weights + self.bias\n",
    "    \"\"\"\n",
    "tokenizer.tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef493c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/tokenizer_python_52k/tokenizer_config.json',\n",
       " '../data/tokenizer_python_52k/special_tokens_map.json',\n",
       " '../data/tokenizer_python_52k/vocab.json',\n",
       " '../data/tokenizer_python_52k/merges.txt',\n",
       " '../data/tokenizer_python_52k/added_tokens.json',\n",
       " '../data/tokenizer_python_52k/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the tokenizer to disk\n",
    "tokenizer.save_pretrained(\"../data/tokenizer_python_52k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0c5a2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd8eca60e304df68ecc6335d7218b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/tensor-polinomics/tokenizer_python_52k/commit/84d21af557eba3635dbad11da610d307dbdb01d4', commit_message='Upload tokenizer', commit_description='', oid='84d21af557eba3635dbad11da610d307dbdb01d4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/tensor-polinomics/tokenizer_python_52k', endpoint='https://huggingface.co', repo_type='model', repo_id='tensor-polinomics/tokenizer_python_52k'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload to Hugging Face Hub\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tokenizer.push_to_hub(\n",
    "    \"tensor-polinomics/tokenizer_python_52k\",\n",
    "    token=os.getenv(\"HF_TOKEN_WRITE\")  # Bypasses all cached credentials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2eae2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n"
     ]
    }
   ],
   "source": [
    "# BatchEncoding object example\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "example = \"Hugging Face's transformers library is among the greatest!\"\n",
    "encoding = tokenizer(example)\n",
    "print(type(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad383088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bafa6b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'hugging', 'face', \"'\", 's', 'transformers', 'library', 'is', 'among', 'the', 'greatest', '!', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# We can access tokens directly\n",
    "print(encoding.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "876dd2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e07bd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '81', 's', '</s>']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_roberta = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "example_short = \"81s\"\n",
    "encoding_roberta = tokenizer_roberta(example_short)\n",
    "encoding_roberta.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb0552ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '81', '##s', '[SEP]']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_bert = tokenizer(example_short)\n",
    "encoding_bert.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30fd6ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 2 corresponds to characters from 28 to 35: 'k at Hu'\n"
     ]
    }
   ],
   "source": [
    "start, end = encoding.word_to_chars(5)\n",
    "print(f\"Token 2 corresponds to characters from {start} to {end}: '{example[start:end]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfb7913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'I-PER',\n",
       "  'score': np.float32(0.99938285),\n",
       "  'index': 4,\n",
       "  'word': 'S',\n",
       "  'start': 11,\n",
       "  'end': 12},\n",
       " {'entity': 'I-PER',\n",
       "  'score': np.float32(0.99815494),\n",
       "  'index': 5,\n",
       "  'word': '##yl',\n",
       "  'start': 12,\n",
       "  'end': 14},\n",
       " {'entity': 'I-PER',\n",
       "  'score': np.float32(0.99590707),\n",
       "  'index': 6,\n",
       "  'word': '##va',\n",
       "  'start': 14,\n",
       "  'end': 16},\n",
       " {'entity': 'I-PER',\n",
       "  'score': np.float32(0.99923277),\n",
       "  'index': 7,\n",
       "  'word': '##in',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.9738931),\n",
       "  'index': 12,\n",
       "  'word': 'Hu',\n",
       "  'start': 33,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.976115),\n",
       "  'index': 13,\n",
       "  'word': '##gging',\n",
       "  'start': 35,\n",
       "  'end': 40},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': np.float32(0.9887976),\n",
       "  'index': 14,\n",
       "  'word': 'Face',\n",
       "  'start': 41,\n",
       "  'end': 45},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': np.float32(0.9932106),\n",
       "  'index': 16,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline example\n",
    "from transformers import pipeline\n",
    "token_classifier = pipeline(\"token-classification\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "example = \"My name is Sylvain and I work at Hugging Face in Brooklyn.\"\n",
    "token_classifier(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d388fd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9981694),\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.9796019),\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.9932106),\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_classifier = pipeline(\"token-classification\", aggregation_strategy=\"simple\")\n",
    "token_classifier(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82ad1506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[  101,  1422,  1271,  1110,   156,  7777,  2497,  1394,  1105,   146,\n",
       "           1250,  1120, 20164, 10932, 10289,  1107,  6010,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
       " TokenClassifierOutput(loss=None, logits=tensor([[[ 8.7508, -2.2626, -1.5300, -2.2889, -0.6513, -2.0016, -0.0112,\n",
       "           -2.0860,  0.3335],\n",
       "          [ 8.4973, -2.3986, -1.3582, -2.7887,  0.7575, -1.8873,  0.4344,\n",
       "           -1.9900, -0.3397],\n",
       "          [ 9.4719, -2.2261, -0.9849, -2.6116,  0.1219, -2.0627, -0.1259,\n",
       "           -1.8758, -0.0609],\n",
       "          [ 9.8670, -2.2175, -1.3125, -2.4866, -0.2550, -1.8536,  0.0856,\n",
       "           -1.7520, -0.6437],\n",
       "          [-0.2011, -2.1873, -1.5316, -2.7110,  8.4025, -2.4168, -0.6980,\n",
       "           -3.0337, -0.0997],\n",
       "          [ 0.1065, -2.0520, -1.4787, -2.8139,  7.4525, -2.8399, -0.0626,\n",
       "           -3.3666, -0.4683],\n",
       "          [ 0.5985, -2.2538, -1.1926, -3.0111,  7.0070, -2.8675,  0.3492,\n",
       "           -3.3129, -0.2878],\n",
       "          [-0.0584, -2.2660, -1.4335, -3.1940,  8.3225, -2.6212, -0.0348,\n",
       "           -2.9780, -0.2957],\n",
       "          [ 9.6889, -2.4281, -1.5653, -2.5225, -0.9693, -1.5668,  0.4285,\n",
       "           -1.9413, -0.6774],\n",
       "          [ 9.0116, -2.1216, -1.4140, -2.6964,  0.2728, -1.7851,  0.3635,\n",
       "           -1.8407, -0.5922],\n",
       "          [ 9.5258, -2.2616, -1.4557, -2.9603, -0.1311, -1.7799,  0.9169,\n",
       "           -2.2549, -0.9692],\n",
       "          [ 9.1087, -2.2834, -1.3437, -2.8742, -0.2521, -1.5712,  1.1501,\n",
       "           -2.0786, -0.8658],\n",
       "          [ 2.5185, -3.1537, -1.6923, -3.4240,  1.4335, -1.8089,  6.5008,\n",
       "           -3.0264, -0.2619],\n",
       "          [ 1.7707, -2.4992, -0.1088, -3.2825,  0.4034, -1.4262,  5.9701,\n",
       "           -2.6502, -0.1259],\n",
       "          [ 0.6466, -2.9276, -0.1020, -3.0776,  0.7036, -1.2746,  6.3889,\n",
       "           -2.7266,  0.3822],\n",
       "          [ 9.2571, -2.6779, -1.2145, -2.7276, -0.9370, -1.5445,  1.1025,\n",
       "           -1.8477, -0.3661],\n",
       "          [-0.2206, -2.5108, -1.2976, -2.9758, -0.5795, -2.2071,  1.8236,\n",
       "           -1.6484,  7.0975],\n",
       "          [ 8.7508, -2.2626, -1.5300, -2.2890, -0.6513, -2.0016, -0.0112,\n",
       "           -2.0860,  0.3335],\n",
       "          [ 8.7508, -2.2626, -1.5300, -2.2889, -0.6513, -2.0016, -0.0112,\n",
       "           -2.0860,  0.3335]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually build up the pipeline\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "inputs = tokenizer(example, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d774a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 19])\n",
      "torch.Size([1, 19, 9])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"].shape)\n",
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a3e4d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)[0].tolist()\n",
    "predictions = outputs.logits.argmax(dim=-1)[0].tolist()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "964991b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-MISC',\n",
       " 2: 'I-MISC',\n",
       " 3: 'B-PER',\n",
       " 4: 'I-PER',\n",
       " 5: 'B-ORG',\n",
       " 6: 'I-ORG',\n",
       " 7: 'B-LOC',\n",
       " 8: 'I-LOC'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38d0648d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'O',\n",
       "  'score': 0.9994322657585144,\n",
       "  'word': '[CLS]',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9989631175994873,\n",
       "  'word': 'My',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.999708354473114,\n",
       "  'word': 'name',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9998350143432617,\n",
       "  'word': 'is',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9993828535079956,\n",
       "  'word': 'S',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9981548190116882,\n",
       "  'word': '##yl',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.995907187461853,\n",
       "  'word': '##va',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9992327690124512,\n",
       "  'word': '##in',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.999804675579071,\n",
       "  'word': 'and',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9995046854019165,\n",
       "  'word': 'I',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9996776580810547,\n",
       "  'word': 'work',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.999434769153595,\n",
       "  'word': 'at',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9738931059837341,\n",
       "  'word': 'Hu',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9761149883270264,\n",
       "  'word': '##gging',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9887974858283997,\n",
       "  'word': 'Face',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9995326995849609,\n",
       "  'word': 'in',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99321049451828,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9994322657585144,\n",
       "  'word': '.',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity': 'O',\n",
       "  'score': 0.9994322657585144,\n",
       "  'word': '[SEP]',\n",
       "  'start': 28,\n",
       "  'end': 35}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "tokens = inputs.tokens()\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    label = model.config.id2label[pred]\n",
    "    if label != \"0\":\n",
    "        results.append({\n",
    "            \"entity\": label,\n",
    "            \"score\": probabilities[idx][pred],\n",
    "            \"word\": tokens[idx],\n",
    "            \"start\": start,\n",
    "            \"end\": end\n",
    "        })\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bbdf90df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  0],\n",
       "         [ 0,  2],\n",
       "         [ 3,  7],\n",
       "         [ 8, 10],\n",
       "         [11, 12],\n",
       "         [12, 14],\n",
       "         [14, 16],\n",
       "         [16, 18],\n",
       "         [19, 22],\n",
       "         [23, 24],\n",
       "         [25, 29],\n",
       "         [30, 32],\n",
       "         [33, 35],\n",
       "         [35, 40],\n",
       "         [41, 45],\n",
       "         [46, 48],\n",
       "         [49, 57],\n",
       "         [57, 58],\n",
       "         [ 0,  0]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True, return_tensors=\"pt\")\n",
    "offsets = inputs_with_offsets[\"offset_mapping\"]\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "749c89f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yl'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e09f027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugging Face'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[33:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2a851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': '', 'score': nan, 'word': 'My name is Sylvain and I work at Hugging Face in Brooklyn', 'start': 0, 'end': 57}, {'entity': '', 'score': nan, 'word': 'My name is Sylvain and I work at Hugging Face in Brooklyn', 'start': 0, 'end': 57}, {'entity': '', 'score': nan, 'word': 'name is Sylvain and I work at Hugging Face in Brooklyn', 'start': 3, 'end': 57}, {'entity': '', 'score': nan, 'word': 'is Sylvain and I work at Hugging Face in Brooklyn', 'start': 8, 'end': 57}, {'entity': 'PER', 'score': 0.998169407248497, 'word': 'Sylvain', 'start': 11, 'end': 18}, {'entity': '', 'score': nan, 'word': '', 'start': 23, 'end': 18}, {'entity': '', 'score': nan, 'word': '', 'start': 25, 'end': 18}, {'entity': '', 'score': nan, 'word': '', 'start': 30, 'end': 18}, {'entity': 'ORG', 'score': 0.9796018600463867, 'word': 'Hugging Face', 'start': 33, 'end': 45}, {'entity': 'LOC', 'score': 0.99321049451828, 'word': 'Brooklyn', 'start': 49, 'end': 57}, {'entity': '', 'score': nan, 'word': 'My name is Sylvain and I work at Hugging Face in Brooklyn', 'start': 0, 'end': 57}]\n"
     ]
    }
   ],
   "source": [
    "# Manually grouping tokens into entities—this version doesn't work well\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True, return_tensors=\"pt\")\n",
    "tokens = inputs_with_offsets.tokens()\n",
    "offsets = inputs_with_offsets[\"offset_mapping\"][0].tolist()\n",
    "\n",
    "idx = 0\n",
    "while idx < len(predictions):\n",
    "    pred = predictions[idx]\n",
    "    label = model.config.id2label[pred]\n",
    "    \n",
    "    if label != \"0\":\n",
    "        # report the B- or I- label \n",
    "        label = label[2:]\n",
    "        start, _ = offsets[idx]\n",
    "        \n",
    "        # Grab all the tokens labled with I-<label>\n",
    "        all_scores = []\n",
    "        while (\n",
    "            idx < len(predictions) and\n",
    "            model.config.id2label[predictions[idx]] == f\"I-{label}\"\n",
    "        ):\n",
    "            all_scores.append(probabilities[idx][pred])\n",
    "            _, end = offsets[idx]\n",
    "            idx += 1\n",
    "            \n",
    "        # The score is the meean of all the scores of the tokens in that group entity\n",
    "        score = np.mean(all_scores).item()\n",
    "        word = example[start:end]\n",
    "        results.append({\n",
    "            \"entity\": label,\n",
    "            \"score\": score,\n",
    "            \"word\": word,\n",
    "            \"start\": start,\n",
    "            \"end\": end\n",
    "        })\n",
    "    idx += 1\n",
    "    \n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7cd518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.998169407248497, 'word': 'Sylvain', 'start': 11, 'end': 18}, {'entity_group': 'ORG', 'score': 0.9796018600463867, 'word': 'Hugging Face', 'start': 33, 'end': 45}, {'entity_group': 'LOC', 'score': 0.99321049451828, 'word': 'Brooklyn', 'start': 49, 'end': 57}]\n"
     ]
    }
   ],
   "source": [
    "# Improved version that handles missing B- labels\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "results = []\n",
    "inputs_with_offsets = tokenizer(example, return_offsets_mapping=True, return_tensors=\"pt\")\n",
    "tokens = inputs_with_offsets.tokens()\n",
    "offsets = inputs_with_offsets[\"offset_mapping\"][0].tolist()\n",
    "\n",
    "idx = 0\n",
    "while idx < len(predictions):\n",
    "    pred = predictions[idx]\n",
    "    label = model.config.id2label[pred]\n",
    "    \n",
    "    # Start entity on B- OR I- (model skips B- tags)\n",
    "    if label.startswith(\"B-\") or label.startswith(\"I-\"):\n",
    "        entity_type = label[2:]\n",
    "        start, end = offsets[idx]\n",
    "        \n",
    "        all_scores = [probabilities[idx][pred]]\n",
    "        idx += 1\n",
    "        \n",
    "        # Continue while same entity type (I- tag)\n",
    "        while idx < len(predictions):\n",
    "            next_label = model.config.id2label[predictions[idx]]\n",
    "            if next_label == f\"I-{entity_type}\":\n",
    "                all_scores.append(probabilities[idx][predictions[idx]])\n",
    "                _, end = offsets[idx]\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        score = np.mean(all_scores).item()\n",
    "        word = example[start:end]\n",
    "        results.append({\n",
    "            \"entity_group\": entity_type,\n",
    "            \"score\": score,\n",
    "            \"word\": word,\n",
    "            \"start\": start,\n",
    "            \"end\": end\n",
    "        })\n",
    "    else:\n",
    "        idx += 1\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a2183af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label map: {0: 'O', 1: 'B-MISC', 2: 'I-MISC', 3: 'B-PER', 4: 'I-PER', 5: 'B-ORG', 6: 'I-ORG', 7: 'B-LOC', 8: 'I-LOC'}\n",
      "Predictions: [0, 0, 0, 0, 4, 4, 4, 4, 0, 0]\n",
      "Labels: ['O', 'O', 'O', 'O', 'I-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'I-LOC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Check what labels the model actually uses\n",
    "print(\"Label map:\", model.config.id2label)\n",
    "\n",
    "# Check what predictions look like\n",
    "print(\"Predictions:\", predictions[:10])\n",
    "print(\"Labels:\", [model.config.id2label[p] for p in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a12b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
